{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different Callbacks to be called during Learning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#fastai callbacks\n",
    "from PrimeCNNv3.imports import *\n",
    "from PrimeCNNv3.utils.vizualize import plot_loss_update\n",
    "from PrimeCNNv3.metric import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Callbacks(GetAttr): _default='learner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SetupLearnerCB(Callbacks):\n",
    "    def before_fit(self):\n",
    "        self.learner.mb = master_bar(range(self.epochs))\n",
    "        self.model.to(self.device)        \n",
    "        \n",
    "    def before_batch(self):\n",
    "    \n",
    "        xb, yb = self.batch\n",
    "        self.learner.xb = xb.to(self.device, non_blocking = True)\n",
    "        self.learner.yb = yb.to(self.device, non_blocking = True)\n",
    "    \n",
    "    def before_train_epoch(self):\n",
    "        self.model.train()\n",
    "        self.learner.training = True\n",
    "    \n",
    "    def before_valid_epoch(self):\n",
    "        self.model.eval()\n",
    "        self.learner.training = False\n",
    "   \n",
    "    def after_validation(self):\n",
    "        pass\n",
    "      #  self.mb.write(f'Epoch: {self.epoch}, Training Loss: {self.epoch_loss.train[-1]}, validation Loss: {self.epoch_loss.valid[-1]}, Training Accuracy: {self.epoch_acc.train[-1]}, Validation Accuracy: {self.epoch_acc.valid[-1]}')\n",
    "      #  plot_loss_update(self.epoch, self.epochs,self.mb, train_loss=self.epoch_loss.train,valid_loss=self.epoch_loss.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Recorder(Callbacks):\n",
    "    '''Records loss and lrs'''\n",
    "    def __init__(self):\n",
    "        self.loss = TrackTrainVal()\n",
    "        \n",
    "        \n",
    "        #track loss across an epoch\n",
    "        self.track_loss = AvgLosses()\n",
    "        \n",
    "        self.track_train_smoothLoss = AvgSmoothLoss()\n",
    "        self.epoch_metricTracker = TrackTrainVal()\n",
    "        \n",
    "        self.accumetric = AccumMetric()\n",
    "        \n",
    "       \n",
    "        \n",
    "    def before_fit(self):\n",
    "        self.learner.losses = self.loss\n",
    "        self.losses.reset()\n",
    "        self.track_loss.reset()\n",
    "        self.track_train_smoothLoss.reset()\n",
    "        self.epoch_metricTracker.reset()\n",
    "        \n",
    "        self.learner.lrs = []\n",
    "        self.learner.train_iter = 0\n",
    "   \n",
    "    def before_epoch(self):\n",
    "        self.accumetric.reset()\n",
    "        self.start_epoch = time.time()\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        self.learner.log = [self.epoch, round(self.losses.train[-1],6), round(self.losses.valid[-1],6)]\n",
    "      \n",
    "        for met in self.metric:\n",
    "            m = round(met(preds = self.accumetric.value[0], target = self.accumetric.value[1]),6)\n",
    "            self.learner.log.append(m)\n",
    "            \n",
    "        self.learner.log.append(format_time(time.time() - self.start_epoch))\n",
    "        \n",
    "    \n",
    "    def before_valid_epoch(self):\n",
    "        self.track_loss.reset()\n",
    "        \n",
    "    \n",
    "    def after_train_epoch(self):\n",
    "        #self.learner.losses.train.append(self.track_train_smoothLoss.value)\n",
    "        pass\n",
    "    \n",
    "    def after_valid_epoch(self):\n",
    "        self.losses.valid.append(self.track_loss.value)\n",
    "        \n",
    "    def after_batch(self):\n",
    "        if self.training:\n",
    "            \n",
    "            self.learner.train_iter += 1\n",
    "            #send leaner to track_loss \n",
    "            \n",
    "            #track learning rate\n",
    "            self.learner.lrs.append(self.opt.param_groups[0]['lr'])\n",
    "            \n",
    "            #track smoothloss for plotting\n",
    "            self.track_train_smoothLoss.value = self.learner\n",
    "            self.losses.train.append(self.track_train_smoothLoss.value)\n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            self.track_loss.value = self.learner\n",
    "            self.accumetric.value = self.learner\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ShowStats(Callbacks):\n",
    "    def before_fit(self):\n",
    "        \n",
    "        self.header_line =  ['Epoch', 'train_loss', 'valid_loss','accuracy','precision','recall','f1_score', 'time']\n",
    "        # loop over metric and add function name to header_line\n",
    "        self.bs = []\n",
    "        self.learner.log = []\n",
    "        self.mb.write(self.header_line, table = True)\n",
    "    def after_train_epoch(self):\n",
    "        self.bs.append(self.train_iter)\n",
    "        \n",
    "    def after_epoch(self):\n",
    "        plot_loss_update(nbs_batches = self.bs, epochs = self.epochs, mb = self.mb, \n",
    "                         train_loss = self.losses.train, valid_loss = self.losses.valid)\n",
    "        \n",
    "        self.mb.write(self.log, table = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TrackTrainVal:\n",
    "    '''Wrapper to store train/valid stats'''\n",
    "    def __init__(self):\n",
    "        self.train, self.valid = [],[]\n",
    "\n",
    "    def reset(self):\n",
    "        self.train.clear()\n",
    "        self.valid.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AvgMetric:\n",
    "    '''Average metric tracking'''\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.bs_counter = 0\n",
    "        self.total = 0.\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.total / self.bs_counter\n",
    "    \n",
    "    @value.setter\n",
    "    def value(self, learn):\n",
    "        self.total += self.func(learn.preds, learn.yb)\n",
    "        self.bs_counter += learn.batch_size\n",
    "    \n",
    "    def reset(self):\n",
    "        self.bs_counter = 0\n",
    "        self.total = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AccumMetric:\n",
    "    '''\n",
    "        Accumulate prediction and target\n",
    "        apply func to get the metric\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.hist_preds = []\n",
    "        self.hist_target = []\n",
    "        self.preds = []\n",
    "        self.target = []\n",
    "        \n",
    "    @property\n",
    "    def value(self):\n",
    "        return torch.cat(self.preds), torch.cat(self.target)\n",
    "    \n",
    "    @value.setter\n",
    "    def value(self, learn):\n",
    "        self.preds.append(learn.preds.cpu().detach())\n",
    "        self.target.append(learn.yb.cpu().detach())\n",
    "       \n",
    "        \n",
    "    def reset(self):\n",
    "        self.hist_preds.extend(self.preds)\n",
    "        self.hist_target.extend(self.target)\n",
    "        self.preds.clear()\n",
    "        self.target.clear()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AvgLosses:\n",
    "    '''keep track of losses'''\n",
    "    #used to print loss stats after each epoch\n",
    "    def __init__(self):\n",
    "        self.bs_counter = 0\n",
    "        self.total = 0.\n",
    "        \n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.total / self.bs_counter\n",
    "    \n",
    "    @value.setter\n",
    "    def value(self, learn):\n",
    "        self.total += learn.running_loss * learn.batch_size\n",
    "        self.bs_counter += learn.batch_size\n",
    "        \n",
    "    def reset(self):\n",
    "        self.bs_counter = 0\n",
    "        self.total = 0.\n",
    "\n",
    "class AvgSmoothLoss:\n",
    "    ''' exponentially weigth loss'''\n",
    "    #mainly used for plotting the loss grpah w.r.t iteration\n",
    "    def __init__(self, beta = 0.98):\n",
    "        '''\n",
    "            Args:\n",
    "                beta: for exponentially weighted average\n",
    "        '''\n",
    "        self.smoothloss = torch.tensor(0)\n",
    "        self.counter = 0\n",
    "        self.beta = beta\n",
    "        \n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.smoothloss / (1 - self.beta**self.counter)\n",
    "    \n",
    "    @value.setter\n",
    "    def value(self, learn):\n",
    "        self.counter += 1\n",
    "        #self.smoothloss = (self.smoothloss * self.beta) + ((1 - self.beta) * learn.running_loss)\n",
    "        #lerp\n",
    "        self.smoothloss = learn.running_loss + self.beta * (self.smoothloss - learn.running_loss)\n",
    "        \n",
    "    def reset(self, beta = 0.98):\n",
    "        self.counter = 0\n",
    "        self.smoothloss = 0\n",
    "        self.beta = beta\n",
    "                                                               \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.data.dataset.ipynb.\n",
      "Converted 01_utils.data.dataloaders.ipynb.\n",
      "Converted 02_utils.vizualize.ipynb.\n",
      "Converted 03_callbacks.ipynb.\n",
      "Converted 04_learner.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
